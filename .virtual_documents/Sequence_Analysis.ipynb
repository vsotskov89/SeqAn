





import numpy as np
import matplotlib.pyplot as plt
import matplotlib.cm as colormap
import pickle
from matplotlib.backends.backend_pdf import PdfPages
#from sklearn.manifold import TSNE
#import sklearn.cluster as hdbscan
#import hdbscan
#from spot import spot, tools
from scipy.io import loadmat, savemat
from scipy import ndimage
from scipy.stats import median_abs_deviation as mad
from scipy.stats import kendalltau, spearmanr, linregress
from utils import *
from events import *

root = '/export/home1/Sequences/NewCNMF/'
#root = '/home/vladimir/Sequences/'
#root = 'D:\\Work\\Sequence analysis\\'


#Load matlab workspaces with full-featured analysis (including ripples and SCEs) of sleep session alone 
#and with place fields of that neurons in awake session
sleep_mat = loadmat(root + 'SleepPOST_all_data_new_CNMF.mat')
pf_mat = loadmat(root + 'Neurons_PFs_separate_CNMF.mat')
#csv reading
SL_time = np.genfromtxt(root + 'sleeppost_070_30_bwf_140_traces.csv', skip_header = 0, delimiter = ',')[:,0]
SL_traces = np.genfromtxt(root + 'sleeppost_070_30_bwf_140_traces.csv', skip_header = 0, delimiter = ',')[:,1:].T

#load matching file
match = np.genfromtxt(root + 'matching.csv', skip_header = 0, delimiter = ',').T
m_ind = match[0]*match[1]

awake_list = (match[0][m_ind > 0]).astype(int) - 1
sleeppost_list = (match[1][m_ind > 0]).astype(int) - 1
n_neurons = len(awake_list)


#Calculate events for the selected traces
opts = {'thr_ampl': 3,     #threshold for peaks in Median Absolute Deviations (MADs)
        'thr_der' : 1.5,     #threshold for derivative in Median Absolute Deviations (MADs)
        'sigma' : 2,     #smoothing parameter for peak detection, frames
        'max_k': 1,      #maximal pre-event slope, normed by thr_peak*MAD/est_ton
        'fit_wnd' : 10,
        'draw': False,   #whether to draw smoothed traces, peaks, pits and fits 
        'output_name': root + 'SL_events_blinfit.html'} 
SL_events_blinfit = SearchEventsByLinearCross(SL_time, SL_traces, opts)
with open(root + 'SL_events_blinfit_test.pickle', "wb") as f:
    pickle.dump(SL_events_blinfit, f)


#The same but with various sigma's
sig_list = [3, 4, 5, 6, 2] #values of sigma to test
opts = {'thr_ampl': 3,     #threshold for peaks in Median Absolute Deviations (MADs)
        'thr_der' : 1.5,     #threshold for derivative in Median Absolute Deviations (MADs)
        'sigma' : 3,     #smoothing parameter for peak detection, frames
        'max_k': 1,      #maximal pre-event slope, normed by thr_peak*MAD/est_ton
        'fit_wnd' : 10,
        'draw': False,   #whether to draw smoothed traces, peaks, pits and fits 
        'output_name': root + 'SL_events_blinfit.html'} 
for sig in sig_list:
    opts['sigma'] = sig
    SL_events_blinfit = SearchEventsByLinearCross(SL_time, SL_traces, opts)
    savemat(root + f'SL_events_sigma_{sig}.mat', {'Evts' : SL_events_blinfit})


#Calculate events for the selected traces'
opts = {'thr_peak': 3,     #threshold for peaks in Median Absolute Deviations (MADs)
        'thr_der' : 1.5,     #threshold for derivative in Median Absolute Deviations (MADs)
        'sigma' : 3,     #smoothing parameter for peak detection, frames
        'est_ton' : 0.001, #estimated event rising time, s
        'est_toff' : 0.1,  #estimated event decay time, s
        'max_k': 0.5,  #maximal pre-event slope, normed by thr_peak*MAD/est_ton
        'fit_window_left' : 10,
        'fit_window_right': 100,
        'draw': True,   #whether to draw smoothed traces, peaks, pits and fits 
        'output_name': 'events_test_dfit.html'} 
SL_events_dfit = SearchEventsDerivativeFit(SL_time, SL_traces[0:5], opts)


#load events from pickle
with open(root + 'SL_events_blinfit.pickle','rb') as f:
    SL_events_blinfit = pickle.load(f,)
    SL_events = [[evt['t0'] for evt in evts] for evts in SL_events_blinfit]    


#load events from external csv file
SL_spikes = np.genfromtxt(root + 'sleeppost_070_30_bwf_140_spikes.csv', skip_header = 1, delimiter = ',')[:,1:].T 
#SL_events = [np.where(sp >0)[0] for sp in SL_spikes]


#OR, load derivative-calculated events
SL_spikes = np.zeros(SL_traces.shape)
for i in range(SL_traces.shape[0]):
    inds = sleep_neurs_der['Neurons']['Rises'][0,0]['Starts'][i,0][0]
    SL_spikes[i,inds] = 1


# Draw traces, events and ripples
import bokeh.plotting as bpl
fact = 2

bpl.output_file(root + 'sleeppost_matched_evts_blinfit.html')
tools = ["pan", "box_zoom", "zoom_in", "zoom_out", "reset"]
p = bpl.figure(title = 'sleeppost matched cells only', tools = tools, height = 1000, width = 1900)#, width_policy = 'fit')
p.vstrip(x0 = sleep_mat['ripples'][:,0], x1 = sleep_mat['ripples'][:,2], line_color = None, fill_color="gray") 

for i, i_neur in enumerate(sleeppost_list):  
    evts = np.array([evt['t0'] for evt in SL_events_blinfit[i_neur]])
    p.line(SL_time, SL_traces[i_neur]*fact/np.max(SL_traces[i_neur]) + i, line_color = Colornum_Mos_Metro(i), line_width = 2)
    p.scatter(evts, i - 0.1, line_color = None, fill_color = Colornum_Mos_Metro(i), size = 5)

p.line(sleep_mat['ePhysData'][:,0], sleep_mat['ePhysData'][:,1]/np.max(sleep_mat['ePhysData'][:,1]) + i + 2, line_color = 'black', line_width=2)
bpl.show(p)





#calculate c.o.m. of all valid place fields for each neuron in each direction
dirlen = {0:93, 1:96} #number of spatial bins in both directions
pfcm = []  #2xnNeurons array of place field centers of mass for both directions for each neuron
pfdistrib = []   #2xnNeurons array of activity distributions across track for both directions for each neuron
stab_distrib = []    #list of stabilitiy values for all valid PFs of all neurons in both directions
width_distrib = []   #list of place field widths for all valid PFs of all neurons in both directions
tot_width_distrib = []   #list of sums of all place fields of 1 place cell widths for all valid PFs of all neurons in both directions
pf_order = []     #order of place fields in both directions
for i_dir in range(2):
    pfcm_dir = []
    pfdistrib_dir = []
    for i_neur in awake_list:
        pfs = pf_mat['Neurons']['PFs'][0, 0][i_neur, 0][i_dir]
        ispcs = pf_mat['Neurons']['isPC'][0, 0][i_neur, 0][i_dir]
        stabs = pf_mat['Neurons']['Stab'][0, 0][i_neur, 0][i_dir]
        distr = pf_mat['Neurons']['NormedSummedPlaceActivity'][0,0][0, i_neur][i_dir][0]
        neur = []
        tot_width = 0
        for pf, ispc, stab in zip(pfs, ispcs, stabs):  #loop for all PFs of a neuron i_neur in direction i_dir 
            if ispc[0][0][0]:   #here shold be a check for thresholds
                neur += pf[0][0].tolist()
                stab_distrib.append(stab[0][0][0])
                width_distrib.append(len(pf[0][0]))  
                tot_width += len(pf[0][0])

        cm = np.nan if not len(neur) else np.argmax(distr)
        #pfcm_dir.append(np.mean(neur)) 
        pfcm_dir.append(cm)
        pfdistrib_dir.append(distr)
        tot_width_distrib.append(tot_width)
    pfcm.append(pfcm_dir)
    pfdistrib.append(pfdistrib_dir)
    pf_order.append(np.argsort(pfcm_dir))


#Plot place field distributions
plt.figure(figsize = (20,20), dpi = 100)
fig, axes = plt.subplots(1,2, sharey = True)
for i_dir, distr in enumerate(pfdistrib):
    axes[i_dir].imshow(np.array(distr)[pf_order[i_dir]], aspect = 5)
    axes[i_dir].set_title(f'Direction {i_dir}')
    axes[i_dir].set_ylabel('Neurons')
    axes[i_dir].set_xlabel('Position, cm')





#First, define ripple and around-ripple epochs:
#the latter are the epochs of the fixed length (duration) centered at the center of the ripple
duration = 0.15 #around-ripple epoch duration in seconds
rip_starts = []  #RELATIVE ripple starts (to the peak of the ripple), in seconds, precise
rip_ends = []    #RELATIVE ripple ends (to the peak of the ripple), in seconds, precise
ep_starts = []   #starts of around-ripple epochs in frames
ep_traces = []   #array of traces sized n_ripples x n_neurons x duration_frames 
fps = 100 
duration_frames = int(duration*fps)
n_epochs = len(sleep_mat['ripples'])

neurotime = sleep_mat['TTLstartsTimes']
def time2ind(t):
    return np.where(neurotime >= t)[0][0]

norm_sl_traces = np.array([(tr - min(tr))/(max(tr) - min(tr)) for tr in SL_traces])
ep_evt_times = []

for ripple in sleep_mat['ripples']:
    rip_starts.append(ripple[0] - ripple[1] + duration/2)
    rip_ends.append(ripple[2] - ripple[1] + duration/2)
    ep_starts.append(time2ind(ripple[1] - duration/2))
    ep_traces.append(norm_sl_traces[sleeppost_list, ep_starts[-1]: ep_starts[-1] + duration_frames])
    ep_evt_times.append([[evt['t0'] for evt in tr_evt if evt['t0'] > ripple[1] - duration/2 and evt['t0'] < ripple[1] + duration/2] for tr_evt in SL_events_blinfit])
ep_traces = np.array(ep_traces)


#Order the epochs by the slope of the events in it, derived by linear regression
pfdir = 1
linfits = []
slopes = []
for epoch in ep_evt_times:
    pts = np.array([[evt, i_tr] for i_tr, trace_num in enumerate(sleeppost_list[pf_order[pfdir]]) for evt in epoch[trace_num] if not np.isnan(pfcm[pfdir][pf_order[pfdir][i_tr]])]).T
    if len(pts):
        linfits.append(linregress(pts[1], pts[0]))
        slopes.append(linfits[-1].slope)
    else:
        linfits.append(np.nan)
        slopes.append(np.nan)
ep_order = np.argsort(slopes)


epoch = ep_evt_times[28]
pts = np.array([[evt, i_tr] for i_tr, trace_num in enumerate(sleeppost_list[pf_order[pfdir]]) for evt in epoch[trace_num] if not np.isnan(pfcm[pfdir][pf_order[pfdir][i_tr]])]).T
pts


linfits[28].slope
#linfits[28].intercept


#Heatmap of the ep_traces
eps_per_row = 10 #number of epochs per row
eps_per_col = 3  #number of epochs per column
eps_per_fig = eps_per_row*eps_per_col
n_pages = int(len(ep_starts)/eps_per_fig) + 1

pfdir = 0
pdf = PdfPages(root + f'Traces_heatmap_dir{pfdir}.pdf')

for page in range(n_pages):
    fig, axes = plt.subplots(eps_per_col, eps_per_row, figsize = (8,11), dpi = 150, sharey = True)
    fig.suptitle(f'Epochs {page*eps_per_fig} - {min((page +1)*eps_per_fig, len(ep_starts))}, in natural order\n Neurons coloured by PFs in direction {pfdir}')
   
    for i_epoch, epoch in enumerate(ep_traces[page*eps_per_fig: min((page +1)*eps_per_fig, n_epochs)]):
        row = int(i_epoch/eps_per_row)
        col = i_epoch%eps_per_row

        axes[row,col].set_xticks([duration_frames/2])
        axes[row,col].set_xticklabels([str(i_epoch + page*eps_per_fig)])
        if not col:
            axes[row,col].set_ylabel('Neurons, sorted')
        #epoch_norm = np.array([(tr-min(tr))/(max(tr) - min(tr)) for tr in ]) #trace-wise normalization   
        axes[row,col].imshow(epoch[pf_order[pfdir]], interpolation = 'none', aspect = 2.0)
    pdf.savefig()
pdf.close()


#Traces and events map

eps_per_row = 10 #number of epochs per row
eps_per_col = 3  #number of epochs per column
eps_per_fig = eps_per_row*eps_per_col
n_pages = int(len(ep_starts)/eps_per_fig) + 1
fact = 10 #scale factor for plotting of the traces

pfdir = 1
colors = ['black' if np.isnan(pf) else colormap.rainbow(pf/dirlen[pfdir])[:3] for pf in pfcm[pfdir]]


pdf = PdfPages(root + f'Traces_events_blinfit_test_dir{pfdir}.pdf')

for page in range(n_pages):
    fig, axes = plt.subplots(eps_per_col, eps_per_row, figsize = (8,11), dpi = 150, sharey = True)
    fig.suptitle(f'Epochs {page*eps_per_fig} - {min((page +1)*eps_per_fig, len(ep_starts))}, in natural order\n Neurons coloured by PFs in direction {pfdir}')
   
    for i_epoch, epoch in enumerate(ep_traces[page*eps_per_fig: min((page +1)*eps_per_fig, n_epochs)]):
        row = int(i_epoch/eps_per_row)
        col = i_epoch%eps_per_row
        time = SL_time[ep_starts[i_epoch+ page*eps_per_fig]:ep_starts[i_epoch+ page*eps_per_fig] + duration_frames]
        axes[row,col].set_xticks([time[int(duration_frames/2)]])
        axes[row,col].set_xticklabels([str(i_epoch + page*eps_per_fig)])
        if not col:
            axes[row,col].set_ylabel('Neurons, sorted')
        #epoch_norm = np.array([(tr-min(tr))/(max(tr) - min(tr)) for tr in ]) #trace-wise normalization   
        #axes[row,col].imshow(epoch[pf_order[pfdir]], interpolation = 'none', aspect = 2.0)
        for i_tr, trace in enumerate(epoch[pf_order[pfdir]]):
            axes[row,col].plot(time, (trace - min(trace))*fact + i_tr, lw = 0.5, color = colors[pf_order[pfdir][i_tr]])
            for ev in ep_evt_times[i_epoch+ page*eps_per_fig][sleeppost_list[pf_order[pfdir][i_tr]]]:
                axes[row, col].scatter(ev, i_tr, color=colors[pf_order[pfdir][i_tr]], marker='.', s=10)
        axes[row, col].axvspan(rip_starts[i_epoch+ page*eps_per_fig] + time[0], rip_ends[i_epoch+ page*eps_per_fig]+time[0], color='gray', alpha=0.5, lw=0)
        #draw a linear fit of all events within the epoch
        try:
            fits = (time - linfits[i_epoch+ page*eps_per_fig].intercept)/linfits[i_epoch+ page*eps_per_fig].slope
            axes[row, col].plot(time, fits, lw = 0.5, color = 'black')
            axes[row, col].set_ylim(0, n_neurons) 
        except:
            continue
    
    pdf.savefig()
pdf.close()





np.gradient([0,1,4,9,16,25],[0,1,2,3,4,5])


from events import SearchEventsInSitu

sd_dict = {'thr_abs': 0.2,   #threshold for peaks in maximal amplitudes of the epoch trace 
           'fit_window': 5,   #half-width of the fitting window, frames
           'sigma' : 1,     #smoothing parameter for peak detection, frames
           'est_ton' : 0.005, #estimated event rising time, s
           'est_toff' : 0.1,  #estimated event decay time, s
           'draw_details': False} #whether to draw smoothed traces, peaks, pits and fits 

ep_evts = []

for i_epoch, epoch in enumerate(ep_traces):
    time = SL_time[ep_starts[i_epoch]:ep_starts[i_epoch] + duration_frames]
    ep_evts.append(SearchEventsInSitu(time - time[0], epoch, opts = sd_dict))


#Plotting
eps_per_row = 10 #number of epochs per row
eps_per_col = 2  #number of epochs per column
eps_per_fig = eps_per_row*eps_per_col
n_pages = int(len(ep_starts)/eps_per_fig) + 1
fact = 0.8 #scale factor for raw calcium plotting

pfdir = 0
pdf = PdfPages(root + f'Epochwise_traces_events_dir{pfdir}.pdf')
colors = ['black' if np.isnan(pf) else colormap.rainbow(pf/dirlen[pfdir])[:3] for pf in pfcm[pfdir]]

for page in range(n_pages):
    fig, axes = plt.subplots(eps_per_col, eps_per_row, figsize = (8,11), dpi = 150, sharey = True)
    fig.suptitle(f'Epochs {page*eps_per_fig} - {min((page +1)*eps_per_fig, len(ep_starts))}, in natural order\n Neurons coloured by PFs in direction {pfdir}')
   
    for i_epoch, epoch in enumerate(ep_traces[page*eps_per_fig: min((page +1)*eps_per_fig, n_epochs)]):
        row = int(i_epoch/eps_per_row)
        col = i_epoch%eps_per_row

        time = SL_time[ep_starts[i_epoch]:ep_starts[i_epoch] + duration_frames]

        axes[row,col].set_xticks([(time[0] + time[-1])/2])
        axes[row,col].set_xticklabels([str(i_epoch + page*eps_per_fig)])
        if not col:
            axes[row,col].set_ylabel('Neurons, sorted')


        axes[row,col].set_xlim(time[0], time[-1])
        axes[row,col].set_ylim(0, n_neurons)
        
        for i_tr, tr in enumerate(epoch[pf_order[pfdir]]):
            trace_norm = np.array((tr-min(tr))/(max(tr) - min(tr))) #trace-wise normalization   
            axes[row,col].plot(time, trace_norm + i_tr, lw = 0.5, color = colors[pf_order[pfdir][i_tr]])
            for ev in ep_evts[i_epoch][i_tr]:
                axes[row, col].scatter(ev['t0']+time[0], i_tr, color=colors[pf_order[pfdir][i_tr]], marker='.', s=10)
        axes[row, col].axvspan(rip_starts[i_epoch]+time[0], rip_ends[i_epoch]+time[0], color='gray', alpha=0.5, lw=0)
    pdf.savefig()
pdf.close()


#Construct data structure of spike times as described in SPOTDisClust for further analysis
spike_times = [] #solid massive for all spike times (relative to the epoch start) of all neurons in all epochs
ii_spike_times = [] #indices in spike_times for each neuron in each epoch, like [[[i_start, i_end], [same for the next neuron],..], [same for the next epoch],...]
duration = 0.4 #around-ripple epoch duration in seconds
fps = 100
duration_frames = int(duration*fps)
#n_neurons = len(sleep_mat['EvtStarts'])
n_neurons = len(sleeppost_list)
nbEvents = [] #number of events per epoch
minev = 0 #minimum number of events per epoch
nbEvents_valid =[] #number of events per valid epoch (i.e., passed by minev criterium)
cnt = 0 #counter of spikes
ep_start_list = []

neurotime = sleep_mat['TTLstartsTimes']
#neurotime -= neurotime[0]

def time2ind(t):
    return np.where(neurotime >= t)[0][0]


for ripple in sleep_mat['ripples']:
    epoch = []
    ep_spike_times = []
    ep_start = time2ind(ripple[1]-duration/2)  #epoch start time in indices 
    rip_start = time2ind(ripple[0]) - ep_start #ripple start time in indicices (relative to the epoch start)
    rip_end = time2ind(ripple[2]) - ep_start   #ripple end time in indicices (relative to the epoch start)
    
    for i_neur in sleeppost_list:
        events = np.array(SL_spikes[i_neur][ep_start:ep_start + duration_frames])
        
        events[:rip_start] = 0 #drop all the events in the current epoch outside the current ripple
        events[rip_end:] = 0
        
        inds = np.nonzero(events)[0]/fps                #spike times and indices,
        ep_spike_times += inds.tolist()                 #realtive to the epoch start
        epoch.append([cnt, cnt+len(inds)])
        cnt += len(inds)
        
    if len(ep_spike_times) >= minev:
        spike_times += ep_spike_times
        ii_spike_times.append(epoch)
        nbEvents_valid.append(len(ep_spike_times))
        ep_start_list.append(ep_start)
    else:
        cnt -= len(ep_spike_times)
        
    nbEvents.append(len(ep_spike_times))
        
ii_spike_times = np.array(ii_spike_times)
nbEpochs = len(nbEvents_valid)
print(f'Constructed {nbEpochs} epochs from {len(nbEvents)} ripples\nFound {sum(nbEvents_valid)} events, av. {sum(nbEvents_valid)/nbEpochs:.1f} per epoch')


#construction of ripple-wise array of precise event times
precise_evts = []
for i_neur in sleeppost_list:
    events = np.array(SL_events_blinfit[i_neur])
    evts2 = []
    for ripple in sleep_mat['ripples']:
        evts1 = events[events > ripple[1] - duration/2]
        evts1 = evts1[evts1 < ripple[1] + duration/2] - ripple[1] + duration/2
        evts2.append(evts1)
    precise_evts.append(evts2)
            


rip_starts = []
rip_ends = []
for ripple in sleep_mat['ripples']:
    rip_starts.append(ripple[0] - ripple[1] + duration/2)
    rip_ends.append(ripple[2] - ripple[1] + duration/2)


ax = plt.subplot()
ax.hist(nbEvents)
ax.set_title('Events per ripple epoch distribution')
ax.set_ylabel('Epochs')
ax.set_xlabel('Events per epoch');


plt.figure(figsize = (6,5), dpi = 100)
ax = plt.subplot()
ax.set_title('Sum of all ripple epoch events')

sum_events = np.zeros((n_neurons, duration_frames)) 
for epoch in ii_spike_times:
    for i_neuron, neuron in enumerate(epoch):
        sp_indices = spike_times[neuron[0]:neuron[1]]
        for ind in sp_indices:
            sum_events[i_neuron, int(ind*fps)] += 1

plt.imshow(sum_events, aspect = 0.3) 
plt.colorbar().set_label('nbEvents')
plt.xlabel('Time, frames')
plt.ylabel('Neurons');


#deduct the order from the neuron-wise center of mass of summary events image
sum_cim = [ndimage.center_of_mass(row)[0] for row in sum_events]
order = np.argsort(sum_cim)


#center of mass of the first epoch
first_cim = [np.mean(spike_times[row[0]:row[1]]) for row in ii_spike_times[0]] 
order = np.argsort(first_cim)


pfdir = 0


pfdir = 1


dirlen = {0:93, 1:96}

colors = ['black' if np.isnan(pf) else colormap.rainbow(pf/dirlen[pfdir])[:3] for pf in pfcm[pfdir]]
col_order = np.argsort(pfcm[pfdir])

#First, sort epochs by Kendall's Tau Sortedness measure OR by Sperman Ranking test
#In fact, order of cell firing of each epoch and of pfcm sorting is compared and epochs are sorted with this obtained measure

ep_sortedness = []
for i_epoch, epoch in enumerate(ii_spike_times):
    active = [i for i, row in enumerate(epoch) if row[0] != row[1]]
    cim = [np.mean(spike_times[row[0]:row[1]]) for row in epoch] #center of mass of the activation times of each neuron
    neur_order = np.argsort([cim[i] for i in active])   #order of active neurons by c.m. of activation times (only active neurons are taken!!)
    loc_col_order = np.argsort([pfcm[pfdir][i] for i in active]) #order of the same neurons by their pfcm in awake session
    #ep_sortedness.append(kendalltau(neur_order, loc_col_order)[0])
    ep_sortedness.append(spearmanr(neur_order, loc_col_order).correlation)

ep_order = np.argsort(ep_sortedness) #oreder of epochs by theis sortedness, i.e. by the similarity of their orders (neur and loc_col)



#Search for the maximal length of sorted subsequence in eavh epoch 
#Sequence = monotonic interval among sorted cells
from scipy.signal import find_peaks

pfdir = 1

dirlen = {0:93, 1:96}

colors = ['black' if np.isnan(pf) else colormap.rainbow(pf/dirlen[pfdir])[:3] for pf in pfcm[pfdir]]
col_order = np.argsort(pfcm[pfdir])


def find_monotonous_intervals(arr):
    peaks, _ = find_peaks(arr, height=0)
    split_lists = np.split(arr, peaks)
    return [list(l) for l in split_lists]

sequences = []
max_length = []

for i_epoch, epoch in enumerate(ii_spike_times): 
    act_neurons = [i for i, row in enumerate(epoch[col_order]) if row[0] != row[1]]
    act_times = [np.mean(spike_times[row[0]:row[1]]) for row in epoch[col_order] if row[0] != row[1]] #center of mass of the activation times of each neuron
    
    sequences.append(find_monotonous_intervals(act_times))
    max_length.append(max([len(seq) for seq in sequences[-1]]))
    
ep_order = np.argsort(max_length)[::-1] #Descending order       
        


#Spatial 2D representation of epochs
interval = 0.4 #length between epoch centers on the plot, s
eps_per_row = 10 #number of epochs per row
eps_per_col = 3  #number of epochs per column
eps_per_fig = eps_per_row*eps_per_col
n_pages = int(len(ii_spike_times)/eps_per_fig) + 1
fact = 0.8 #scale factor for raw calcium plotting
tracelen = int(interval*fps) + 1
pfdir = 0
dirlen = {0:93, 1:96}


pdf = PdfPages(root + f'WTraces_natural_dir{pfdir}_evts_fit_4_4.pdf')

for page in range(n_pages):
    fig, axes = plt.subplots(eps_per_col, 1, figsize = (8,11), dpi = 150)
    fig.suptitle(f'Epochs {page*eps_per_fig} - {min((page +1)*eps_per_fig, len(ii_spike_times))}, in natural order\n Neurons coloured by PFs in direction {pfdir}')
    
    for a, ax in enumerate(axes):
        ax.set_xticks(np.linspace(interval, eps_per_row*interval, eps_per_row))
        ax.set_xticklabels([str(i + a*eps_per_row + page*eps_per_fig) for i in range(eps_per_row)])
        ax.set_xlim(interval*0.5, interval*(eps_per_row + 0.5))
        ax.set_ylim(0, n_neurons)
        ax.set_ylabel('Neurons, sorted')
    axes[-1].set_xlabel('Epochs')

    for i_epoch, epoch in enumerate(ii_spike_times[page*eps_per_fig: min((page +1)*eps_per_fig, len(ii_spike_times))]):
        row = int(i_epoch/eps_per_row)
        col = i_epoch%eps_per_row
        axes[row].axvline(interval*(col + 1.5), c = 'black', linewidth=0.5)
        ep_start = ep_start_list[i_epoch + page*eps_per_fig]
        for i_neuron, neuron in enumerate(epoch[col_order]):
            trace = SL_traces[sleeppost_list[col_order[i_neuron]],:][ep_start:ep_start + duration_frames]
            #spikes = np.array(spike_times[neuron[0]:neuron[1]])
            #axes[row].scatter(spikes + interval*(col + 0.5), np.ones(len(spikes))+i_neuron, color=colors[col_order[i_neuron]], marker='.', s=10)
            evts = precise_evts[col_order[i_neuron]][i_epoch + page*eps_per_fig] #NB!! Works only if n_epochs == n_ripples
            axes[row].scatter(evts + interval*(col + 0.5), np.ones(len(evts))+i_neuron-1, color=colors[col_order[i_neuron]], marker='.', s=10)
            axes[row].plot(np.linspace(interval*(col + 0.5), interval*(col + 0.5) + duration, duration_frames), trace*fact/np.max(np.fabs(trace)) + i_neuron, color=colors[col_order[i_neuron]], linewidth=0.5)
        axes[row].axvspan(rip_starts[i_epoch + page*eps_per_fig]+ interval*(col + 0.5), rip_ends[i_epoch + page*eps_per_fig]+ interval*(col + 0.5), color='gray', alpha=0.5, lw=0)
    pdf.savefig()
pdf.close()


#Colored representation of epochs
interval = 0.1 #length between epoch centers on the plot
eps_per_row = 25 #number of epochs per row
eps_per_col = 4  #number of epochs per column
eps_per_fig = eps_per_row*eps_per_col
n_pages = int(len(ii_spike_times)/eps_per_fig) + 1

pdf = PdfPages(root + f'Chrp_spearmanr_dir{pfdir}.pdf')

for page in range(n_pages):
    fig, axes = plt.subplots(eps_per_col, 1, figsize = (8,11), dpi = 150)
    fig.suptitle(f'Epochs {page*eps_per_fig} - {min((page +1)*eps_per_fig, len(ii_spike_times))}, sorted by Spearman R\n Neurons coloured by PFs in direction {pfdir}')
    
    for a, ax in enumerate(axes):
        ax.set_xticks(np.linspace(interval, eps_per_row*interval, eps_per_row))
        ax.set_xticklabels([str(i + a*eps_per_row + page*eps_per_fig) for i in range(eps_per_row)])
        ax.set_xlim(interval*0.5, interval*(eps_per_row + 0.5))
        ax.set_ylim(0, n_neurons)
        ax.set_ylabel('Neurons, sorted')
    axes[-1].set_xlabel('Epochs')

    for i_epoch, epoch in enumerate(ii_spike_times[ep_order[page*eps_per_fig: min((page +1)*eps_per_fig, len(ii_spike_times))]]):
        row = int(i_epoch/eps_per_row)
        col = i_epoch%eps_per_row
        axes[row].axvline(interval*(col + 0.5), c = 'black', linewidth=0.5)

        cim = [np.mean(spike_times[row[0]:row[1]]) for row in epoch] 
        order = np.argsort(cim)
        for i_neuron, neuron in enumerate(epoch[order]):
            spikes = np.array(spike_times[neuron[0]:neuron[1]])
            axes[row].scatter(spikes + interval*col, np.ones(len(spikes))+i_neuron, color=colors[order[i_neuron]], marker='.', s=10)
    pdf.savefig()
pdf.close()


#Spatial 2D representation of epochs
interval = 0.1 #length between epoch centers on the plot
eps_per_row = 10 #number of epochs per row
eps_per_col = 5  #number of epochs per column
eps_per_fig = eps_per_row*eps_per_col
n_pages = int(len(ii_spike_times)/eps_per_fig) + 1

pdf = PdfPages(root + f'Chrp_2D_monoton_dir{pfdir}.pdf')

for page in range(n_pages):
    fig, axes = plt.subplots(eps_per_col, 1, figsize = (8,11), dpi = 150)
    fig.suptitle(f'Epochs {page*eps_per_fig} - {min((page +1)*eps_per_fig, len(ii_spike_times))}, sorted by the longest monotonous interval\n Neurons coloured by PFs in direction {pfdir}')
    
    for a, ax in enumerate(axes):
        ax.set_xticks(np.linspace(interval, eps_per_row*interval, eps_per_row))
        ax.set_xticklabels([str(i + a*eps_per_row + page*eps_per_fig) for i in range(eps_per_row)])
        ax.set_xlim(interval*0.5, interval*(eps_per_row + 0.5))
        ax.set_ylim(0, n_neurons)
        ax.set_ylabel('Neurons, sorted')
    axes[-1].set_xlabel('Epochs')

    for i_epoch, epoch in enumerate(ii_spike_times[ep_order][page*eps_per_fig: min((page +1)*eps_per_fig, len(ii_spike_times))]):
        row = int(i_epoch/eps_per_row)
        col = i_epoch%eps_per_row
        axes[row].axvline(interval*(col + 0.5), c = 'black', linewidth=0.5)
        for i_neuron, neuron in enumerate(epoch[col_order]):
            spikes = np.array(spike_times[neuron[0]:neuron[1]])
            axes[row].scatter(spikes + interval*col, np.ones(len(spikes))+i_neuron, color=colors[col_order[i_neuron]], marker='.', s=10)
    pdf.savefig()
pdf.close()


#Now the same, but in both directions simultaneously
interval = 0.1 #length between epoch centers on the plot
eps_per_row = 10 #number of epochs per row
eps_per_col = 5  #number of epochs per column
eps_per_fig = eps_per_row*eps_per_col
n_pages = int(len(ii_spike_times)/eps_per_fig) + 1
spacing = 5

pdf = PdfPages(root + f'Chrp_2D_bidirectional.pdf')

dirlen = {0:93, 1:96}
markers = {0:'^', 1: 'v'}

for page in range(n_pages):
    fig, axes = plt.subplots(eps_per_col, 1, figsize = (8,11), dpi = 150)
    fig.suptitle(f'Epochs {page*eps_per_fig} - {min((page +1)*eps_per_fig, len(ii_spike_times))}\n PFs of each neuron are paired by color, black = unidirectional place cell')
    
    for a, ax in enumerate(axes):
        ax.set_xticks(np.linspace(interval, eps_per_row*interval, eps_per_row))
        ax.set_xticklabels([str(i + a*eps_per_row + page*eps_per_fig) for i in range(eps_per_row)])
        ax.set_xlim(interval*0.5, interval*(eps_per_row + 0.5))
        ax.set_ylim(-spacing, n_neurons+ spacing)
        ax.set_ylabel('Neurons, sorted')
    axes[-1].set_xlabel('Epochs')

    for i_epoch, epoch in enumerate(ii_spike_times[page*eps_per_fig: min((page +1)*eps_per_fig, len(ii_spike_times))]):
        row = int(i_epoch/eps_per_row)
        col = i_epoch%eps_per_row
        axes[row].axvline(interval*(col + 0.5), c = 'black', linewidth=0.5)

        for i_neuron, neuron in enumerate(epoch):
            spikes = np.array(spike_times[neuron[0]:neuron[1]])
            color = colormap.rainbow(np.mean([pfcm[pfdir][i_neuron]/dirlen[pfdir] for pfdir in range(2)]))[:3]
            height = []
            for pfdir in range(2):
                if np.isnan(pfcm[pfdir][i_neuron]):
                    continue
                height.append(int(pfcm[pfdir][i_neuron]/dirlen[pfdir]*n_neurons))
                axes[row].scatter(spikes + interval*col, np.ones(len(spikes))+height[-1], color=color, marker=markers[pfdir], s=10)
            if len(height) > 1:
                for sp in spikes:
                    axes[row].axvline(sp + interval*col, ymin=(height[0] + spacing)/(n_neurons + 2*spacing), ymax=(height[1] + spacing)/(n_neurons + 2*spacing), color=color, linestyle = '--', linewidth =0.5, zorder = 0)
    pdf.savefig()
pdf.close()





dissimilarities = spot.distances(spike_times, ii_spike_times, metric='SPOTD_xcorr')
plt.imshow(dissimilarities, cmap='PuBu')


clusterer = hdbscan.HDBSCAN(metric='precomputed')
cluster_labels = clusterer.fit_predict(np.nan_to_num(dissimilarities))
clusters = np.unique(cluster_labels)

print(len(clusters), 'clusters found')
for cl in clusters:
    print(f'Cluster # {cl} :{len(np.where(cluster_labels==cl)[0])} epochs') 
    


si = np.argsort(cluster_labels)
plt.title('Sorted SPOTDis matrix')
plt.imshow(dissimilarities[:, si][si], cmap='PuBu')
plt.colorbar().set_label('SPOTDis')
plt.xlabel('Epoch')
plt.ylabel('Epoch');


embedding = TSNE(n_components=2).fit_transform(np.nan_to_num(dissimilarities))
plt.scatter(embedding[:, 0], embedding[:, 1], cmap='Set1_r', c=cluster_labels)
plt.colorbar()


#show events distribution in clusters made of ripple and random epochs
cluster_event_sums = []    
n_clust = len(clusters)
figure, axes = plt.subplots(2,n_clust, figsize=(10, 10), dpi=150)
figure.suptitle('Clusters summary, neurons unsorted')
for icl, clust in enumerate(clusters):
    events2d = np.zeros((n_neurons, duration_frames))
    for nb_epoch in np.where(cluster_labels==clust)[0]:
        for i_neuron, neuron in enumerate(ii_spike_times[nb_epoch]):
            sp_indices = spike_times[neuron[0]:neuron[1]]
            for ind in sp_indices:
                events2d[i_neuron, int(ind*fps)] += 1
    plot = axes[0, icl].imshow(events2d, aspect = 0.5) 
    plt.colorbar(plot, ax=axes[0, icl]).set_label('nbEvents')
    axes[1, icl].bar(np.linspace(0,19,20), np.sum(events2d, axis = 0))
    cluster_event_sums.append(events2d)
    


#show events distribution in clusters made of ripple and random epochs
figure, axes = plt.subplots(1,n_clust, figsize=(10, 5), dpi=150)
figure.suptitle('Clusters summary, neurons sorted by pfcm dir 2')
for icl, clust_sum in enumerate(cluster_event_sums):
    #order = np.argsort(first_times)
    first_times = [0 if not np.count_nonzero(row) else np.nonzero(row)[0][0] for row in clust_sum]
    #order = np.argsort(first_times)
    plot = axes[icl].imshow(clust_sum[order, :], aspect = 0.62) 
    plt.colorbar(plot, ax=axes[icl]).set_label('nbEvents')



#show events distribution in clusters made of ripple and random epochs
figure, axes = plt.subplots(1,n_clust, figsize=(10, 5), dpi=150)
figure.suptitle('Clusters summary, neurons sorted by first event across all epochs')
for icl, clust_sum in enumerate(cluster_event_sums):
    first_times = [0 if not np.count_nonzero(row) else np.nonzero(row)[0][0] for row in clust_sum]
    order = np.argsort(first_times)
    plot = axes[icl].imshow(clust_sum[order, :], aspect = 0.62) 
    plt.colorbar(plot, ax=axes[icl]).set_label('nbEvents')



#Sort epochs by Kendall's Tau Sortedness measure OR by Sperman Ranking test
ep_order = []
for cl in clusters:
    ep_sortedness = []
    cl_indices = np.where(cluster_labels==cl)[0]
    for i_epoch, epoch in enumerate(ii_spike_times[cl_indices]):
        active = [i for i, row in enumerate(epoch) if row[0] != row[1]]
        cim = [np.mean(spike_times[row[0]:row[1]]) for row in epoch] 
        neur_order = np.argsort([cim[i] for i in active])   #order by c.m. of activation times (only active neurons are taken!!)
        loc_col_order = np.argsort([pfcm[pfdir][i] for i in active]) 
        #ep_sortedness.append(kendalltau(neur_order, col_order)[0])
        ep_sortedness.append(spearmanr(neur_order, loc_col_order).correlation)
    ep_order.append(np.argsort(ep_sortedness))


#Plot raster map of all epochs in .pdf files 
interval = 0.1 #length between epoch centers on the plot
eps_per_row = 25 #number of epochs per row
eps_per_col = 4  #number of epochs per column
eps_per_fig = eps_per_row*eps_per_col

pdf = PdfPages(root + 'Chrp_spearmanr_dir0.pdf')

for i_cl, cl in enumerate(clusters):
    cl_indices = np.where(cluster_labels==cl)[0]
    n_pages = int(len(cl_indices)/eps_per_fig) + 1
    for page in range(n_pages):
        fig, axes = plt.subplots(eps_per_col, 1, figsize = (8,11), dpi = 150)
        fig.suptitle('Cluster #' + str(cl))
        for a, ax in enumerate(axes):
            #ax.set_xticks(np.linspace(interval, eps_per_row*interval, eps_per_row), labels = [str(i + a*eps_per_row + page*eps_per_fig) for i in range(eps_per_row)])
            ax.set_xlim(interval*0.5, interval*(eps_per_row + 0.5))
            ax.set_ylim(0, n_neurons)
            ax.set_xlabel('Epochs')
            ax.set_ylabel('Neurons')
                         
        for i_epoch, epoch in enumerate(ii_spike_times[cl_indices[ep_order[i_cl]][page*eps_per_fig: min((page +1)*eps_per_fig, len(cl_indices))]]):
            row = int(i_epoch/eps_per_row)
            col = i_epoch%eps_per_row
            axes[row].axvline(interval*(col + 0.5), c = 'black', linewidth=0.5)
            
            cim = [np.mean(spike_times[row[0]:row[1]]) for row in epoch] 
            order = np.argsort(cim)
            for i_neuron, neuron in enumerate(epoch[order]):
                spikes = np.array(spike_times[neuron[0]:neuron[1]])
                axes[row].scatter(spikes + interval*col, np.ones(len(spikes))+i_neuron, color=colors[order[i_neuron]], marker='.', s=10)
        pdf.savefig()
pdf.close()





shape = (269,272)
thres = 0.5
color = np.array([1,0,1])
A = sleep_mat['ExtractedResults']['A'][0][0][:,5].todense().reshape(shape)
B = (A/np.max(A) > thres)
B = np.moveaxis(np.array(([B,]*3))*1.0, 0, 2)*color


plt.imshow(B)


#Plot all selected neurons on the FOV and color them with respect to their PFs in both directions separately
shape = (269,272)
thres = 0.5
dirlen = {0:93, 1:96}

plt.figure(figsize = (20,10), dpi = 100)
fig, axes = plt.subplots(1,2, sharey = True)

for pfdir in range(2):
    colors = [[0.5,0.5,0.5] if np.isnan(pf) else colormap.rainbow(pf/dirlen[pfdir])[:3] for pf in pfcm[pfdir]]
    IM = np.zeros((*shape, 3))
    for i_neur, neur in enumerate(pc_list):
        A = sleep_mat['ExtractedResults']['A'][0][0][:,neur].todense().reshape(shape)
        A = (A/np.max(A) > thres)
        IM += np.moveaxis(np.array(([A,]*3))*1.0, 0, 2)*colors[i_neur]
    axes[pfdir].imshow(IM)
    axes[pfdir].set_title(f'Direction {pfdir}')



def clnm(num):
    #Returns color for each number as in Moscow Metro
    return {
    1:"red",        
    2:"green",      
    3:"mediumblue",        
    4:"cyan",        
    5:"sienna", 
    6:"darkorange",    
    7:"mediumvioletred",      
    8:"gold",   
    9:"magenta",
    0:"lawngreen"}.get(num%10)   

def DrawSpEvents(time, traces, events):
    bpl.output_notebook()
    #bpl.output_file(root + 'traces__events.html')    
    p = bpl.figure(title = 'Traces and events', width_policy = 'fit')
    for cell_num, (trace, evts) in enumerate(zip(traces, events)):
        p.line(time, trace/np.max(trace) + cell_num, line_color = clnm(cell_num))
        p.scatter(time[evts>0], cell_num - 0.1, line_color = None, fill_color = clnm(cell_num), size = 5)
    bpl.show(p)


import bokeh.plotting as bpl


time = sleep_mat['TTLstartsTimes'][:,0]
traces = sleep_mat['ExtractedResults']['C'][0][0][pc_list,:] 
events = sleep_mat['EvtStarts'][pc_list]

#DrawSpEvents(time, traces, events)

bpl.output_notebook()
#bpl.output_file(root + 'traces__events.html')    
p = bpl.figure(title = 'Traces and events', width = 1200)#, )# width_policy = 'fit')
for cell_num, (trace, evts) in enumerate(zip(traces, events)):
    p.line(time, trace/np.max(trace) + cell_num, line_color = clnm(cell_num))
    p.scatter(time[evts>0], cell_num - 0.1, line_color = None, fill_color = clnm(cell_num), size = 5)
bpl.show(p)


plt.plot(time, trace/np.max(trace) + cell_num, color = clnm(cell_num))


plt.scatter(time[evts>0], cell_num - 0.1)




